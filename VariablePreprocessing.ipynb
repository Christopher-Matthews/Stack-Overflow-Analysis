{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Basic Data Prep for Modeling\n",
    "### Based on Stack Overflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "\n",
    "df0 = pd.read_csv('./survey_results_public.csv')\n",
    "df_schema = pd.read_csv('./survey_results_schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_function(df):\n",
    "    '''\n",
    "    INPUT: Raw dataframe from stack exchange\n",
    "    \n",
    "    OUTPUT: Dataframe cleaned in an appropriate manner for future\n",
    "            analysis. Some data points might be excluded or columns\n",
    "            transformed.\n",
    "    '''\n",
    "#     current analysis focused on us working population\n",
    "    df = df[(\n",
    "        df.EmploymentStatus.ne('Not employed, and not looking for work')&\n",
    "        df.EmploymentStatus.ne('Not employed, but looking for work')&\n",
    "        df.EmploymentStatus.ne('Retired')&\n",
    "        df.Country.eq('United States')\n",
    "        )] \n",
    "    \n",
    "#     drop if JobSatisfaction outcomes is missing this is the \n",
    "#     outcome of interest\n",
    "    df = df.loc[df['JobSatisfaction'].isnull() == False, :]\n",
    "#     Only 6 missing values going to drop the nulls here for ease \n",
    "#     since its the Ind Var we want to interpret I don't want to guess/\n",
    "#     estimate/impute this one in this exercise\n",
    "    df = df.loc[df['HomeRemote'].isnull() == False, :]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaning_function(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #For Visual detailed inspection of variables to see how answers\n",
    "# #are structured on the survey\n",
    "\n",
    "# for col_name in enumerate(df.columns[1:(len(df.columns)-1)]):\n",
    "    \n",
    "#     unique_values = len(df[col_name[1]].unique())\n",
    "#     missing = df[col_name[1]].isnull().sum()\n",
    "    \n",
    "#     print('{} values in ***{}*** ({} missing)'\n",
    "#           .format(unique_values, col_name[1], missing))\n",
    "# #     print('QUESTION: ',df_schema.iloc[col_name[0],1])\n",
    "# #     for i in range(unique_values):\n",
    "# #         print(df[col_name[1]].unique()[i])\n",
    "# #         print('====')\n",
    "# #     print(df[col_name[1]].unique())\n",
    "#     print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After Visual Inspection\n",
    "\n",
    "think about including:\n",
    "\n",
    "    - AsessJobRemote what are the pros and cons of leaving this out\n",
    "    - CollaborateRemote\n",
    "    \n",
    "exclude: \n",
    "\n",
    "    - country\n",
    "\n",
    "modify/research: \n",
    "\n",
    "    - (hours per week /Salary/ExpectedSalary) \n",
    "        needs to be dummied there is too many missing values\n",
    "        do some research on it and think of a way to bucket\n",
    "    - need to condense DeveloperType before dummy\n",
    "    - ImportantBenefits: need to condense or drop (there is also \n",
    "        remote) options in this variable - maybe break down \n",
    "        the individual dummies and also how many options were \n",
    "        selected as an engineered feature\n",
    "    - job profile: consider the same as importantBenefits\n",
    "    - EducationTypes: same as above\n",
    "    - SelfTaughtTypes same as above\n",
    "    - CousinEducation same as above\n",
    "    - HaveWorkedLanguage\n",
    "    - WantWorkLanguage\n",
    "    - HaveWorkedFramework\n",
    "    - WantWorkFramework\n",
    "    - HaveWorkedDatabase\n",
    "    - WantWorkDatabase\n",
    "    - Have/Want Work Platform\n",
    "    - IDE\n",
    "    - Methodology\n",
    "    - MetricAssess\n",
    "    - StackOverflowDevices\n",
    "    - Gender\n",
    "    - Race\n",
    "    \n",
    "keep the same:\n",
    "\n",
    "    - Categoricals with less than 25 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to be able to say something for how an increase in remote working can influence a workers job satisfaction. This will be less a prediction task and more an inference task. I like using linear regression for these tasks because of the ease of interpretability. \n",
    "\n",
    "If we broke each column out into dummy variables we would have more columns then rows and using linear regression would not be appropriate. I like the 10:1 variable to observation rule which means we should look to include no more than about 36 variables as controls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps and notes:\n",
    "\n",
    "- Step1: see if there is a way to collapse some columns. After inspection there are 2 columns that are numeric that I want to bucket that will need inspection (HoursPerWeek/Salary. There are some categoricals with multiple answers I will find the unique values and condense the dummy columns into less granular columns which could help reduce the feature space.\n",
    "- Step2: Create a variable importance to help sort through the variables and help chose the best n variables. remember we will be creating dummy variables for home remote status because that is the independent variable of interest. There are 7 categories and we need to drop 1 for interpretation (Never) which means max were going to use 30 other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start with the 3 numeric columns I need to bucket: HoursPerWeek, Salary. Here I show Visual inspection of the data to get close to even categories in HoursPerWeek. I applied the same process to the other 2 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Numerics that need to be binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_viewer(df, col_string):\n",
    "    print(\n",
    "        list(\n",
    "            df_schema[\n",
    "                df_schema\n",
    "                .Column\n",
    "                .eq(col_string)]['Question']))\n",
    "    print('\\nColumn Stats \\n\\n', df[col_string].describe())\n",
    "    \n",
    "    df[col_string].plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During a typical week, approximately how many hours do you spend on activities related to finding new job opportunities?Please adjust the slider to the appropriate number of hours. The box to the right will indicate the number of hours you have chosen.']\n",
      "\n",
      "Column Stats \n",
      "\n",
      " count    1422.000000\n",
      "mean        2.769339\n",
      "std         5.623937\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         3.000000\n",
      "max        40.000000\n",
      "Name: HoursPerWeek, dtype: float64\n",
      "\n",
      " Cumulative Distribution\n",
      "\n",
      " 0.0     0.119034\n",
      " 1.0     0.231687\n",
      " 2.0     0.293285\n",
      " 3.0     0.314095\n",
      " 4.0     0.334073\n",
      " 5.0     0.352109\n",
      " 6.0     0.358491\n",
      " 7.0     0.361265\n",
      " 8.0     0.367647\n",
      " 9.0     0.368479\n",
      " 10.0    0.377636\n",
      " 11.0    0.378746\n",
      " 12.0    0.380411\n",
      " 13.0    0.381521\n",
      " 15.0    0.383185\n",
      " 18.0    0.383463\n",
      " 20.0    0.387347\n",
      " 21.0    0.387902\n",
      " 23.0    0.388457\n",
      " 30.0    0.388735\n",
      " 32.0    0.389012\n",
      " 38.0    0.389567\n",
      " 39.0    0.389845\n",
      " 40.0    0.394562\n",
      "NaN      1.000000\n",
      "Name: HoursPerWeek, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_viewer(df, 'HoursPerWeek')\n",
    "print('\\n Cumulative Distribution\\n')\n",
    "print((round(df['HoursPerWeek'], -0)\n",
    "       .value_counts(dropna=False)/df['HoursPerWeek']\n",
    "       .shape[0])\n",
    "      .sort_index()\n",
    "      .cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsing variables into less columns\n",
    "\n",
    "The data we were given on some of the variables had multiple repsonses that were vary granular. For instance there might be only 1 person in the data set that was a Developer/Data Scientist/Pick any other of 12 attirbutes. Having dummy variables for each and every possible outcome is a great way to not only add too many variables but to overfit as well. I was able to extract each unique value from the entire set and give each person a value if they mentioned that category. In doing this we reduced the number of categories of the DeveloperType from 440 down to only 14 and kept all the user information! Here is how I arrived at being able to do that. This will be passed into the cleaning_function and will loop over all the columns I want to collapse listed above and return a similar set for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desktop applications developer</th>\n",
       "      <th>DevOps specialist</th>\n",
       "      <th>Embedded applications/devices developer</th>\n",
       "      <th>Other</th>\n",
       "      <th>Quality assurance engineer</th>\n",
       "      <th>Web developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Desktop applications developer  DevOps specialist  \\\n",
       "3                                0                  0   \n",
       "6                                0                  0   \n",
       "10                               0                  0   \n",
       "15                               1                  0   \n",
       "17                               0                  1   \n",
       "18                               0                  0   \n",
       "25                               0                  0   \n",
       "27                               1                  0   \n",
       "29                               0                  0   \n",
       "39                               1                  0   \n",
       "\n",
       "    Embedded applications/devices developer  Other  \\\n",
       "3                                         0      0   \n",
       "6                                         0      0   \n",
       "10                                        0      0   \n",
       "15                                        0      0   \n",
       "17                                        1      1   \n",
       "18                                        0      0   \n",
       "25                                        0      0   \n",
       "27                                        0      0   \n",
       "29                                        0      0   \n",
       "39                                        0      0   \n",
       "\n",
       "    Quality assurance engineer  Web developer  \n",
       "3                            0              0  \n",
       "6                            0              0  \n",
       "10                           0              0  \n",
       "15                           0              0  \n",
       "17                           1              1  \n",
       "18                           0              1  \n",
       "25                           0              1  \n",
       "27                           0              1  \n",
       "29                           0              0  \n",
       "39                           0              0  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of the first 10 users from the dataset\n",
    "# notice for index #17 there are multiple indicators for \n",
    "# developer type. In the original datset these are just stacked\n",
    "# together in a single column as multiple values which makes the\n",
    "# data extremely granular.\n",
    "\n",
    "\n",
    "a = df['DeveloperType'].head(10)\n",
    "a = a.str.split(';')\n",
    "b = list()\n",
    "for i in range(len(a)):\n",
    "#     print(i)\n",
    "#     print(a.iloc[i])\n",
    "#     print(type(a.iloc[i]))\n",
    "    if type(a.iloc[i]) == float:\n",
    "        next\n",
    "#         print('heres a float')\n",
    "    else:\n",
    "#         print(a.iloc[i])\n",
    "        for j in range(len(a.iloc[i])):\n",
    "#             print(a.iloc[i][j])\n",
    "            b.append(a.iloc[i][j].strip())\n",
    "unique_cats = list(np.unique(b))\n",
    "\n",
    "dummy_df = pd.DataFrame(index=np.arange(0,len(a),1))\n",
    "for j in range(len(unique_cats)):\n",
    "    d = list()\n",
    "    for i in range(len(a)):\n",
    "        if type(a.iloc[i]) == float:\n",
    "            d.append(0)\n",
    "        else:\n",
    "            is_in = str(unique_cats[j]) in ''.join(a.iloc[i]) \n",
    "            d.append(int(is_in))\n",
    "    dummy_df = pd.merge(dummy_df, \n",
    "                        pd.DataFrame(d, columns=[unique_cats[j]]), \n",
    "                        right_index=True, \n",
    "                        left_index=True)\n",
    "    \n",
    "    \n",
    "dummy_df.index = a.index\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CareerSatisfaction           float64\n",
       "StackOverflowSatisfaction    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function to help preprocess data\n",
    "\n",
    "def cleaning_function(df):\n",
    "    '''\n",
    "    INPUT: Raw dataframe from stack exchange (2017)\n",
    "    \n",
    "    OUTPUT: Dataframe cleaned in an appropriate manner for future\n",
    "            analysis. Some data points might be excluded or columns\n",
    "            transformed. Categoricals with <25 categories are left\n",
    "            as is while >25 are condensed to include less categories.\n",
    "    '''\n",
    "    original_shape = df.shape\n",
    "#     current analysis focused on us working population\n",
    "    df = df[(\n",
    "        df.EmploymentStatus.ne('Not employed, and not looking for work')&\n",
    "        df.EmploymentStatus.ne('Not employed, but looking for work')&\n",
    "        df.EmploymentStatus.ne('Retired')&\n",
    "        df.Country.eq('United States')\n",
    "        )] \n",
    "    df.drop(['Country'], axis=1, inplace=True)\n",
    "    \n",
    "#     drop if JobSatisfaction outcomes is missing this is the \n",
    "#     outcome of interest\n",
    "    df = df[pd.notnull(df.JobSatisfaction)]\n",
    "    \n",
    "#     Only 6 missing values going to drop the nulls here for ease \n",
    "#     since its the Ind Var we want to interpret I don't want to guess/\n",
    "#     estimate/impute this one in this exercise\n",
    "    df = df[pd.notnull(df.HomeRemote)]\n",
    "    \n",
    "    #Bin certain numberics\n",
    "    hours_per_week = pd.cut(df['HoursPerWeek'], \n",
    "                            [0,1,2,6,20,41],\n",
    "                            labels=['0', '1', '2-5', '6-20', '20+'],\n",
    "                            right=False)\n",
    "    hours_per_week = pd.get_dummies(hours_per_week,\n",
    "                                    prefix='HoursPerWeek',\n",
    "                                    prefix_sep='=',\n",
    "                                    dummy_na=False)\n",
    "    salary = pd.cut(df['Salary'],\n",
    "                    [0,75000,100000,150000,300000],\n",
    "                    labels=['<75k', '75-99k', '100-149k', '150k+'],\n",
    "                    right=False)\n",
    "    salary = pd.get_dummies(salary, \n",
    "                            prefix='Salary',\n",
    "                            prefix_sep='=', \n",
    "                            dummy_na=False)\n",
    "    \n",
    "    #Select unaffected numerica columns\n",
    "    numeric_cols = df['JobSatisfaction']\n",
    "    \n",
    "    #Collapsing multi-select categoricals\n",
    "    cols_to_replace = [\n",
    "        'DeveloperType','ImportantBenefits','JobProfile',\n",
    "        'EducationTypes','SelfTaughtTypes','CousinEducation', \n",
    "        'HaveWorkedLanguage','WantWorkLanguage','HaveWorkedFramework',\n",
    "        'WantWorkFramework','HaveWorkedDatabase','WantWorkDatabase',\n",
    "        'HaveWorkedPlatform','WantWorkPlatform','IDE','Methodology',\n",
    "        'MetricAssess','StackOverflowDevices','Gender','Race']\n",
    "    \n",
    "    master_df = pd.DataFrame(index=np.arange(0,df.shape[0],1))\n",
    "    for k in range(len(cols_to_replace)):\n",
    "        a = df[cols_to_replace[k]]\n",
    "        a = a.str.split(';')\n",
    "        b = list()\n",
    "        for i in range(len(a)):\n",
    "            if type(a.iloc[i]) == float:\n",
    "                next\n",
    "            else:\n",
    "                for j in range(len(a.iloc[i])):\n",
    "                    b.append(a.iloc[i][j].strip())\n",
    "\n",
    "        unique_cats = list(np.unique(b))\n",
    "\n",
    "        dummy_df = pd.DataFrame(index=np.arange(0,len(a),1))\n",
    "        for j in range(len(unique_cats)):\n",
    "            d = list()\n",
    "            for i in range(len(a)):\n",
    "                if type(a.iloc[i]) == float:\n",
    "                    d.append(0)\n",
    "                else:\n",
    "                    is_in = str(unique_cats[j]) in ''.join(a.iloc[i]) \n",
    "                    d.append(int(is_in))\n",
    "\n",
    "            column_names = [cols_to_replace[k] + '=' + unique_cats[j]]\n",
    "            dummy_df = pd.merge(dummy_df, \n",
    "                                pd.DataFrame(d, columns=column_names), \n",
    "                                right_index=True, left_index=True)\n",
    "\n",
    "        master_df = pd.merge(master_df, dummy_df, \n",
    "                             right_index=True,left_index=True)\n",
    "\n",
    "    master_df.index = df.index\n",
    "\n",
    "    #Create a list of categoricals that will be converted to \n",
    "    #simple dummy varabies with no alteration and then convet\n",
    "    keep_same = list()\n",
    "    for col_name in enumerate(df.columns):\n",
    "\n",
    "        unique_values = len(df[col_name[1]].unique())\n",
    "        data_type = df.dtypes[col_name[0]]\n",
    "\n",
    "        cols_to_replace = [\n",
    "            'DeveloperType','ImportantBenefits','JobProfile',\n",
    "            'EducationTypes','SelfTaughtTypes','CousinEducation', \n",
    "            'HaveWorkedLanguage','WantWorkLanguage','HaveWorkedFramework',\n",
    "            'WantWorkFramework','HaveWorkedDatabase','WantWorkDatabase',\n",
    "            'HaveWorkedPlatform','WantWorkPlatform','IDE','Methodology',\n",
    "            'MetricAssess','StackOverflowDevices','Gender','Race',\n",
    "            'CareerSatisfaction', 'StackOverflowSatisfaction']\n",
    "        exclude_these = ['HomeRemote', 'HoursPerWeek', 'Country']\n",
    "\n",
    "        if (unique_values < 26 \n",
    "                and data_type == 'object' \n",
    "                and col_name[1] not in cols_to_replace\n",
    "                and col_name[1] not in exclude_these): \n",
    "            keep_same.append(col_name[1])\n",
    "    \n",
    "    unchanged_dummy = pd.get_dummies(df[keep_same],\n",
    "                                     prefix_sep='=',\n",
    "                                     dummy_na=False)\n",
    "    \n",
    "    #Target columns get special treatment\n",
    "    new_homeRemote_names = {\n",
    "    'Less than half the time, but at least one day each week': \n",
    "        'Remote=1PlusDaysPerWeek',\n",
    "    \"All or almost all the time (I'm full-time remote)\": \n",
    "        'Remote=FullTime',\n",
    "    'A few days each month': 'Remote=FewDaysPerMonth',\n",
    "    'More than half, but not all, the time': 'Remote=MoreThanHalf',\n",
    "    'Never': 'Remote=Never',\n",
    "    \"It's complicated\": 'Remote=ItsComplicated',\n",
    "    'About half the time': 'Remote=HalfTime'\n",
    "    }\n",
    "\n",
    "    homeRemote = (pd\n",
    "                  .get_dummies(df['HomeRemote'])\n",
    "                  .rename(columns=new_homeRemote_names))\n",
    "\n",
    "    #Merge DataFrames on Index\n",
    "    df2 = pd.DataFrame(numeric_cols).merge(pd.DataFrame(hours_per_week), \n",
    "                             left_index=True, right_index=True)\n",
    "    df2 = df2.merge(homeRemote, \n",
    "                    left_index=True, right_index=True)\n",
    "    df2 = df2.merge(pd.DataFrame(salary),\n",
    "                    left_index=True,right_index=True)\n",
    "    df2 = df2.merge(master_df, \n",
    "                    left_index=True, right_index=True)\n",
    "    df2 = df2.merge(unchanged_dummy, \n",
    "                    left_index=True, right_index=True)\n",
    "    print('\\nTransformation Overview:\\n'\n",
    "          'Original dataframe dimension were {0}\\n'\n",
    "          'New dataframe dimension are {1}'\n",
    "          .format(original_shape, df2.shape))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "cleaning_function(df0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
